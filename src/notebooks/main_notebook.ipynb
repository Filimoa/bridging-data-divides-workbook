{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# os.environ[\"OPEN_AI_KEY\"] = \"sk-...\"\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Python in 10 minutes\n",
    "\n",
    "This interface allows you to run Python code interactively and view the results immediately, along with any visualizations or text explanations. Each block of code or text you see is contained in what we call a \"cell.\"\n",
    "\n",
    "## Basic Operations\n",
    "\n",
    "- **Running a Cell**: You can run the code or render the markdown in a cell by selecting it and pressing `Shift + Enter`, or by clicking the \"Run\" button in the toolbar.\n",
    "- **Adding New Cells**: Add a new cell by clicking the \"+\" button in the toolbar.\n",
    "- **Cell Types**: Cells can be code cells or markdown cells. Switch the type using the dropdown in the toolbar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Python Example\n",
    "\n",
    "# Printing a message\n",
    "print(\"Hello, World!\")\n",
    "\n",
    "# Basic arithmetic\n",
    "result = 7 * 6\n",
    "print(\"7 multiplied by 6 is\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Variables\n",
    "\n",
    "# Store a value in a variable\n",
    "a = 10\n",
    "\n",
    "# Use the variable in a calculation\n",
    "b = a * 2\n",
    "\n",
    "# Print the result\n",
    "print(\"The result of a multiplied by 2 is\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Structures\n",
    "\n",
    "# List: an ordered collection of items\n",
    "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
    "print(\"Fruits List:\", fruits)\n",
    "\n",
    "# Dictionary: key-value pairs\n",
    "prices = {\"apple\": 0.40, \"banana\": 0.50, \"cherry\": 0.30}\n",
    "print(\"Fruit Prices:\", prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through a list\n",
    "for fruit in fruits:\n",
    "    print(fruit, \"costs\", prices[fruit], \"each\")\n",
    "\n",
    "# Conditional: if statement\n",
    "if \"banana\" in fruits:\n",
    "    print(\"Yes, we have bananas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Functions\n",
    "\n",
    "Functions are a way to organize your code into blocks that can be called multiple times throughout your program. They allow you to write cleaner, more modular code and make your scripts easier to maintain and debug. Functions in Python are defined using the `def` keyword.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Simple Function\n",
    "\n",
    "\n",
    "def greet(name):\n",
    "    \"\"\"This function greets the person whose name is passed as a parameter\"\"\"\n",
    "    return f\"Hello, {name}! Welcome to our notebook.\"\n",
    "\n",
    "\n",
    "# Calling the function\n",
    "greeting = greet(\"Alice\")\n",
    "print(greeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function with Parameters and Return Value\n",
    "\n",
    "\n",
    "def calculate_area(length, width):\n",
    "    \"\"\"This function returns the area of a rectangle given its length and width.\"\"\"\n",
    "    area = length * width\n",
    "    return area\n",
    "\n",
    "\n",
    "# Using the function\n",
    "rect_area = calculate_area(10, 5)\n",
    "print(\"The area of the rectangle is:\", rect_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging Jupyter-AI for Code Generation\n",
    "\n",
    "Jupyter-AI is an advanced feature integrated into Jupyter Notebooks that helps users write code more efficiently. It utilizes AI technology to suggest code snippets, complete code blocks, and even generate complex code structures.\n",
    "\n",
    "#### How to Use Jupyter-AI to Write Code\n",
    "\n",
    "1. **Initiating Code Suggestions**: Simply start typing your code or a description of the function you need in a code cell. Jupyter-AI will automatically suggest completions.\n",
    "2. **Accepting Suggestions**: When a code suggestion appears, you can press `Tab` to accept it, instantly filling in the suggestion.\n",
    "3. **Chat Interface**: You can also interact with Jupyter-AI using the chat interface on the left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using the autocomplete functioanlity to write a function that adds two numbers\n",
    "\n",
    "\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Try having jupyter AI autocomplete this function.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# Assert statements to check the correctness of the function\n",
    "assert add_numbers(1, 2) == 3, \"Function add_numbers does not work correctly!\"\n",
    "print(\"Function add_numbers works correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're not limited to simple functions. Here's a tricky function with a bug in it. Try pasting it into the chat bar on the left and asking the AI to fix it\n",
    "\n",
    "\n",
    "def factorial(n: int) -> int:\n",
    "    \"\"\"This function has a bug in it. Can you find and fix it with AI?\"\"\"\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        result = 1\n",
    "        for i in range(n):\n",
    "            result *= i\n",
    "        return result\n",
    "\n",
    "\n",
    "# Assert statements to check the correctness of the function\n",
    "assert factorial(0) == 1, \"The factorial of 0 should be 1\"\n",
    "assert factorial(1) == 1, \"The factorial of 1 should be 1\"\n",
    "assert factorial(5) == 120, \"The factorial of 5 should be 120\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get started with the case study!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Architecture\n",
    "\n",
    "The architecture of the system is as follows:\n",
    "\n",
    "1. We chunk up the document into distinct “sections” and embed those sections\n",
    "2. Then, we embed the user query and find the most similar part of the document.\n",
    "3. We feed the original question along with context we found to the LLM and receive an answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What exactly is an embedding?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, NOT_GIVEN\n",
    "import instructor\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#########################\n",
    "### UTILITY FUNCTIONS ###\n",
    "#########################\n",
    "\n",
    "# instantiating the OpenAI client\n",
    "client = instructor.patch(OpenAI(api_key=os.getenv(\"OPEN_AI_KEY\")))\n",
    "batch_size = 250\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "\n",
    "\n",
    "# wrapper function around openai to directly return embedding of text\n",
    "def get_embedding(text: str | list[str], dimensions: int = NOT_GIVEN) -> list[float]:\n",
    "    \"\"\"Get the embedding of the input text.\"\"\"\n",
    "    if dimensions:\n",
    "        assert dimensions <= 3072, \"The maximum number of dimensions is 3072.\"\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        input=text, model=embedding_model, dimensions=dimensions\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "def get_many_embeddings(texts: list[str]) -> list[list[float]]:\n",
    "    \"\"\"Get the embeddings of multiple texts.\"\"\"\n",
    "    batch_size = 250\n",
    "    res = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        api_resp = client.embeddings.create(input=batch_texts, model=embedding_model)\n",
    "        batch_res = [val.embedding for val in api_resp.data]\n",
    "        res.extend(batch_res)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# simple utility function to add a vector to a 3D plot\n",
    "def add_vector_to_graph(\n",
    "    fig: go.Figure, vector: list[float], color: str = \"red\", name: Optional[str] = None\n",
    ") -> go.Figure:\n",
    "    # Ensure vector has exactly three components\n",
    "    assert len(vector) == 3, \"Vector must have exactly 3 components.\"\n",
    "\n",
    "    # Origin point\n",
    "    origin = [0, 0, 0]\n",
    "\n",
    "    # Components of the vector\n",
    "    x_component, y_component, z_component = vector\n",
    "\n",
    "    # Adding the line part of the vector\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[origin[0], x_component],\n",
    "            y=[origin[1], y_component],\n",
    "            z=[origin[2], z_component],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=color, width=5),\n",
    "            name=name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding the cone at the tip of the vector\n",
    "    fig.add_trace(\n",
    "        go.Cone(\n",
    "            x=[x_component],\n",
    "            y=[y_component],\n",
    "            z=[z_component],\n",
    "            u=[x_component],\n",
    "            v=[y_component],\n",
    "            w=[z_component],\n",
    "            sizemode=\"scaled\",\n",
    "            sizeref=0.1,\n",
    "            showscale=False,\n",
    "            colorscale=[[0, color], [1, color]],\n",
    "            hoverinfo=\"none\",\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_new_graph() -> go.Figure:\n",
    "    \"\"\"Create a 3D plotly figure with a simple layout.\"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # make sure the plot isn't rotated\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.5, y=1.5, z=0.5),  # Adjust the camera position\n",
    "                up=dict(x=0, y=0, z=1),  # Sets the z-axis as \"up\"\n",
    "                center=dict(x=0, y=0, z=0),  # Focuses the camera on the origin\n",
    "            ),\n",
    "            aspectmode=\"cube\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a dot at the origin\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[0],\n",
    "            y=[0],\n",
    "            z=[0],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=6, color=\"black\", symbol=\"circle\"),\n",
    "            name=\"Origin\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get started\n",
    "\n",
    "For the purpose of the notebook we're going to use an OpenAI approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try using the get_embedding function\n",
    "result = get_embedding(\"Hello, World!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of numbers! OpenAI embedding support built in dimensionality reduction - let's try using that and visualizing the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_new_graph()\n",
    "\n",
    "text = \"Atlanta\"\n",
    "\n",
    "# Get the embedding of the text\n",
    "vector = get_embedding(text, dimensions=3)\n",
    "\n",
    "# Add the vector to the plot\n",
    "add_vector_to_graph(graph, vector, name=text)\n",
    "\n",
    "# Show the plot\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try plotting a couple vectors at once to see if we can see any patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_new_graph()\n",
    "\n",
    "text = \"Atlanta\"\n",
    "atlanta_vector = get_embedding(text, dimensions=3)\n",
    "add_vector_to_graph(graph, atlanta_vector, name=text, color=\"purple\")\n",
    "\n",
    "text = \"Georgia, USA\"\n",
    "georgia_vector = get_embedding(text, dimensions=3)\n",
    "add_vector_to_graph(graph, georgia_vector, name=text, color=\"blue\")\n",
    "\n",
    "text = \"Skiing in japan\"\n",
    "ski_vector = get_embedding(text, dimensions=3)\n",
    "add_vector_to_graph(graph, ski_vector, name=text, color=\"red\")\n",
    "\n",
    "# Show the plot\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we can quantify the similarity between two vectors? One common way is to use the cosine similarity. The cosine similarity between two vectors is the cosine of the angle between them. It ranges from -1 (opposite directions) to 1 (same direction), with 0 indicating orthogonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(a: list[float], b: list[float]) -> float:\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "# We can use the cosine similarity to compare the similarity between two vectors\n",
    "similarity = cosine_similarity(atlanta_vector, georgia_vector)\n",
    "print(f\"The similarity between 'Atlanta' and 'Georgia, USA' is {similarity:.2f}\")\n",
    "\n",
    "similarity = cosine_similarity(atlanta_vector, ski_vector)\n",
    "print(f\"The similarity between 'Atlanta' and 'Skiing in Japan' is {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Challenges (Optional)\n",
    "\n",
    "#### 1. Sentence Embeddings\n",
    "\n",
    "How does adding words to a sentence affect the embedding vector? Try creating a for loop that adds a word to the text and plots the resulting embedding vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out (implemented solutions can be found in the solutions.ipynb notebook)\n",
    "\n",
    "color_scale = [\n",
    "    \"#E6E6FA\",  # Lavender\n",
    "    \"#D8BFD8\",  # Thistle\n",
    "    \"#DDA0DD\",  # Plum\n",
    "    \"#DA70D6\",  # Orchid\n",
    "    \"#BA55D3\",  # Medium Orchid\n",
    "    \"#9932CC\",  # Dark Orchid\n",
    "    \"#9400D3\",  # Dark Violet\n",
    "    \"#8A2BE2\",  # Blue Violet\n",
    "    \"#800080\",  # Purple\n",
    "    \"#4B0082\"   # Indigo\n",
    "] # each one is progressively darker\n",
    "\n",
    "# choose a sentence\n",
    "\n",
    "# split the sentence into words\n",
    "\n",
    "# iterate across each values, hint use enumerate\n",
    "\n",
    "# create a sub_sentence with the first n words ->  \" \".join(words[:ix])\n",
    "\n",
    "# get the embedding of the sub_sentence\n",
    "\n",
    "# add the vector to the graph, set the color = color_scale[ix]\n",
    "\n",
    "# visualize!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parsing Documents\n",
    "\n",
    "Large language models are currently primarly optimized for working with text. As a result when dealing with documents like PDF's we need to first convert them into a text format before we can feed them into the model.\n",
    "\n",
    "We maintain a popular open source library for doing this called [openparse](https://github.com/Filimoa/open-parse/). It is a simple and easy to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openparse\n",
    "\n",
    "#########################\n",
    "### UTILITY FUNCTIONS ###\n",
    "#########################\n",
    "\n",
    "\n",
    "class VectorDatabase:\n",
    "    \"\"\"\n",
    "    A simple in-memory database to store nodes along with their vectors and perform similarity search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "\n",
    "    def add_node(self, node: openparse.Node) -> None:\n",
    "        \"\"\"Add a node along with its vector to the database.\"\"\"\n",
    "        assert node.embedding is not None, \"Node must have an embedding.\"\n",
    "\n",
    "        for existing_node in self.nodes:\n",
    "            if existing_node.text == node.text:\n",
    "                print(f\"Node with id {node.node_id} already exists. Skipping\")\n",
    "                return\n",
    "\n",
    "        self.nodes.append(node)\n",
    "\n",
    "    def find_node(self, node_id: str):\n",
    "        \"\"\"Retrieve a node by its ID.\"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node.node_id == node_id:\n",
    "                return node\n",
    "        return None\n",
    "\n",
    "    def find_similar_node(\n",
    "        self, input_vector: list[float], top_k: int = 3\n",
    "    ) -> list[openparse.Node]:\n",
    "        \"\"\"Find the top_k nodes with the highest cosine similarity to the input_vector.\"\"\"\n",
    "        assert self.nodes, \"Database is empty. Please add nodes first.\"\n",
    "        assert top_k <= len(\n",
    "            self.nodes\n",
    "        ), \"top_k should be less than or equal to the number of nodes.\"\n",
    "\n",
    "        similarities = []\n",
    "        for node in self.nodes:\n",
    "            similarity = cosine_similarity(input_vector, node.embedding)\n",
    "            similarities.append((node, similarity))\n",
    "\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return [node for node, _ in similarities[:top_k]]\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        \"\"\"Return the number of nodes in the database.\"\"\"\n",
    "        return len(self.nodes)\n",
    "\n",
    "    def delete_all_nodes(self) -> None:\n",
    "        \"\"\"Delete all nodes from the database.\"\"\"\n",
    "        self.nodes = []\n",
    "\n",
    "\n",
    "db = VectorDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openparse\n",
    "\n",
    "doc_path = \"./docs/portland-site-assessment-phase-1.pdf\"\n",
    "pdf = openparse.Pdf(doc_path)\n",
    "parser = openparse.DocumentParser()\n",
    "parsed_doc = parser.parse(doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes are parsed as markdown - bold text is kept. This helps LLM's understand the structure of the document. Let's try looking at the first couple nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in parsed_doc.nodes[10:11]:\n",
    "    display(node)\n",
    "    print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's embed all the nodes and add to the database\n",
    "raw_node_texts = [node.text for node in parsed_doc.nodes]\n",
    "embeddings = get_many_embeddings(raw_node_texts)\n",
    "\n",
    "for node, embedding in zip(parsed_doc.nodes, embeddings):\n",
    "    node.embedding = embedding\n",
    "    db.add_node(node)\n",
    "\n",
    "print(\"=== Database now has \", db.num_nodes, \" nodes ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### UTILITY FUNCTIONS ###\n",
    "#########################\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def get_completion(prompt: str) -> Markdown:\n",
    "    \"\"\"\n",
    "    OpenAI returns a complex object, this is a simple wrapper function to directly return the completion text.\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    cost_dollars = completion.usage.total_tokens / 100_000\n",
    "\n",
    "    print(\n",
    "        f\"Completion used {completion.usage.total_tokens} tokens costing ${cost_dollars:.2f}\"\n",
    "    )\n",
    "    \n",
    "    return Markdown(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "def display_similar_nodes(\n",
    "    similar_nodes: list[openparse.Node], query_vector: list[float], pdf: openparse.Pdf\n",
    ") -> None:\n",
    "    page_nums = set()\n",
    "    annotations = []\n",
    "    for node in similar_nodes:\n",
    "        sim = cosine_similarity(query_vector, node.embedding)\n",
    "        page_nums.add(node.start_page)\n",
    "        page_nums.add(node.end_page)\n",
    "        annotations.append(round(sim, 3))\n",
    "\n",
    "    pdf.display_with_bboxes(similar_nodes, page_nums=page_nums, annotations=annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try asking one of our original questions\n",
    "\n",
    "question = \"Is there lead contamination into the groundwater?\"\n",
    "\n",
    "# Get the embedding of the text\n",
    "query_vector = get_embedding(question)\n",
    "\n",
    "# find the most similar node\n",
    "similar_nodes = db.find_similar_node(query_vector, top_k=5)\n",
    "\n",
    "for node in similar_nodes:\n",
    "    sim = cosine_similarity(query_vector, node.embedding)\n",
    "    print(\n",
    "        f\"Found similar node on page {node.start_page} with a similarity of {sim:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single string of all the similar nodes\n",
    "context = \"\\n\\n\".join([node.text for node in similar_nodes])\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Creating Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add a variable to a string by using format\n",
    "\n",
    "name = \"sergey\"\n",
    "\n",
    "template = \"\"\"{name} is from Denver\"\"\"\n",
    "\n",
    "print(\"Without calling format: \", template)\n",
    "print(\"After calling format: \", template.format(name=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Using the document provided, answer the following question:\n",
    "\n",
    "question: {question}\n",
    "\n",
    "context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok let's try running a completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Using the document provided, answer the following question:\n",
    "\n",
    "question: {question}\n",
    "\n",
    "context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "completion = get_completion(prompt)\n",
    "\n",
    "print(\"Original Question:\", question)\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can display citations showing users exactly where we got our answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_similar_nodes(similar_nodes, query_vector, pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ContainsHazards(BaseModel):\n",
    "    contains_lead: bool\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    response_model=ContainsHazards,\n",
    ")\n",
    "\n",
    "print(response.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.contains_lead:\n",
    "    question = \"What mitigations have been performed up to this point to deal with the lead exposure?\"\n",
    "\n",
    "    query_vector = get_embedding(question)\n",
    "\n",
    "    similar_nodes = db.find_similar_node(query_vector, top_k=5)\n",
    "\n",
    "    context = \"\\n\\n\".join([node.text for node in similar_nodes])\n",
    "\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "    mitigations_performed = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitigations_performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = (\n",
    "    \"Why were the following mitigations to remove the lead from the property ineffective \"\n",
    "    + mitigations_performed.data\n",
    ")\n",
    "\n",
    "query_vector = get_embedding(question)\n",
    "\n",
    "# this is a more complex question, let's expand the search to top 9 nodes\n",
    "similar_nodes = db.find_similar_node(query_vector, top_k=9)\n",
    "\n",
    "context = \"\\n\\n\".join([node.text for node in similar_nodes])\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "failure_reasons = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Limitations to RAG\n",
    "\n",
    "What are some limitations to this approach? Let's discuss with the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Challenges (Optional)\n",
    "\n",
    "#### 1. Let's pass the entire document to ChatGPT and see if we get a different answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try combining all the nodes into one string,\n",
    "# Hint: You can iterate across the original document nodes by using `for node in parsed_doc.nodes:`. Each Node has a `node.text` attribute!\n",
    "\n",
    "# Create a prompt the same way we created one earlier except now pass the full document string\n",
    "\n",
    "# Request a completion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
